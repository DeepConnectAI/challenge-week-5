{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification metrics\n",
    "\n",
    "Choosing right evaluation metrics for the problem is one of the most important aspect of machine learning. Choice of metrics allows us to compare performance of different models and helps in model selection.\n",
    "\n",
    "In this task, we will explore following metrics:\n",
    "- accuracy\n",
    "- precision\n",
    "- recall\n",
    "- f1 score\n",
    "- cross entropy loss\n",
    "- area under roc curve\n",
    "- confusion matrix\n",
    "\n",
    "#### Dataset\n",
    "The training dataset is available at \"data/ozone_levels_train.csv\" in the respective challenge' repo.<br>\n",
    "The testing dataset is available at \"data/ozone_levels_test.csv\" in the respective challenge' repo.\n",
    "\n",
    "The dataset is __modified version__ of the dataset 'ozone level' on provided by UCI Machine Learning repository.\n",
    "Original dataset: https://archive.ics.uci.edu/ml/datasets/Ozone+Level+Detection\n",
    "\n",
    "#### Objective\n",
    "To learn about classification metrics and compare logistic regression and decision tree on the same dataset\n",
    "\n",
    "#### Tasks\n",
    "\n",
    "#### Further fun\n",
    "\n",
    "#### Helpful links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy \n",
    "- Classification accuracy is simply the rate of correct classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_logistic = \n",
    "y_pred_tree = \n",
    "y_true_logistic = \n",
    "y_true_tree ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_logistic_classification_acc = ()*100\n",
    "y_tree_classification_acc = ()*100\n",
    "print(\"classificaton accuracy logistic \",y_logistic_classification_acc)\n",
    "print(\"classificaton accuracy tree \",y_tree_classification_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross entropy loss\n",
    "- Logistic loss is a performance metric for evaluating the predictions of probabilities which states how how much confidence a class can be predicted.\n",
    "- H(P) = â€“ sum x on X p(x) * log(p(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_logistic_classificaion_log_loss = \n",
    "y_tree_classificaion_log_loss = \n",
    "print(\"classificaton accuracy logistic \",y_logistic_classificaion_log_loss)\n",
    "print(\"classificaton accuracy tree \",y_tree_classificaion_log_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area Under ROC Curve\n",
    "- A ROC Curve is a plot of the true positive rate and the false positive rate for a given set of probability predictions at different thresholds used to map the probabilities to class labels. The area under the curve is then the approximate integral under the ROC Curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False positive rate\n",
    "# false positive\n",
    "fp_tree = \n",
    "# true negative\n",
    "tn_tree = \n",
    "fpr_tree = \n",
    "\n",
    "# True positive rate\n",
    "# false positive\n",
    "tp_tree = \n",
    "# true negative\n",
    "fn_tree = \n",
    "tpr_tree = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False positive rate\n",
    "# false positive\n",
    "fp_logistic = \n",
    "# true negative\n",
    "tn_logistic = \n",
    "fpr_logistic = \n",
    "\n",
    "# True positive rate\n",
    "# false positive\n",
    "tp_logistic = \n",
    "# true negative\n",
    "fn_logistic = \n",
    "tpr_logistic = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot a graph between tpr_tree and fpr_tree and compare it with tpr_logistic and fpr_logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot()\n",
    "plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "- A confusion matrix is a technique for summarizing the performance of a classification algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false positive\n",
    "fp_tree = \n",
    "# true negative\n",
    "tn_tree = \n",
    "# false positive\n",
    "tp_tree = \n",
    "# true negative\n",
    "fn_tree = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false positive\n",
    "fp_logistic = \n",
    "# true negative\n",
    "tn_logistic = \n",
    "# false positive\n",
    "tp_logistic = \n",
    "# true negative\n",
    "fn_logistic = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 score\n",
    "- To find the equal balance between precision and recall. F1 score is a harmonic mean of precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_tree = \n",
    "f1_score_logistic = \n",
    "print(\"F1 score tree \",f1_score_tree)\n",
    "print(\"F1 score logistic \",f1_score_logistic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
